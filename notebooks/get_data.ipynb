{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "def load_bnc():\n",
    "    from nltk.corpus.reader import bnc\n",
    "    bnc_reader = bnc.BNCCorpusReader(root='./data/BNC/Texts/', fileids=r'[A-K]/\\w*/\\w*\\.xml')\n",
    "    return bnc_reader #.tagged_sents()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Concreteness ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 39954 words from Brysbaert dataset\n",
      "# unigrams: 37058\n",
      "# bigrams: 2896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'word': 'fire', 'concreteness': 4.68, 'bigram': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONCRETENESS_RATINGS_PATH = '../data/brysbaert/Concreteness_ratings_Brysbaert_et_al_BRM.txt'\n",
    "\n",
    "\n",
    "def load_ratings(path=CONCRETENESS_RATINGS_PATH, override=False):\n",
    "    import csv\n",
    "    #items = []\n",
    "    ratings_dict = {}\n",
    "\n",
    "    with open(CONCRETENESS_RATINGS_PATH, mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file, delimiter='\\t')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            word = row[\"Word\"]\n",
    "            rating = row[\"Conc.M\"]\n",
    "            if float(row[\"Bigram\"]) == 1:\n",
    "                bigram = True\n",
    "            else:\n",
    "                bigram = False\n",
    "            item = {\"word\": word,\n",
    "                    \"concreteness\": float(rating),\n",
    "                    \"bigram\": bigram,\n",
    "                   }\n",
    "            #items.append(item)\n",
    "            ratings_dict[word] = item\n",
    "            line_count+=1\n",
    "    print(\"processed %s words from Brysbaert dataset\" % line_count)\n",
    "    \n",
    "    unigrams = 0\n",
    "    bigrams = 0\n",
    "    for x in ratings_dict.values():\n",
    "        if x[\"bigram\"] == True:\n",
    "               bigrams +=1\n",
    "        else:\n",
    "               unigrams +=1\n",
    "    print(\"# unigrams: %s\" % unigrams)\n",
    "    print(\"# bigrams: %s\" % bigrams)\n",
    "    \n",
    "    \n",
    "    return ratings_dict\n",
    "\n",
    "ratings_dict = load_ratings()\n",
    "\n",
    "ratings[\"fire\"]\n",
    "\n",
    "# TODO what is the relationship between num word pieces and concreteness rating? so magnanimous is rated lower (more abstract) than magnanimously. Are people adding abstractness for extra morphemes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get token contexts for BNC words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly(seq):\n",
    "    import random\n",
    "    shuffled = list(seq)\n",
    "    random.shuffle(shuffled)\n",
    "    return list(shuffled)\n",
    "\n",
    "\n",
    "def current_word(index, sentence):\n",
    "    # the first item in the BNC tuple is the word string\n",
    "    return sentence[index][0]\n",
    "\n",
    "def next_word(index, sentence):\n",
    "    # if we haven't reached the last word, return next word\n",
    "    # the first item in the BNC tuple is the word string\n",
    "    if index < len(sentence) - 1:\n",
    "        return sentence[index+1][0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_biword(current, nextt, bigrams):\n",
    "    if nextt == None:\n",
    "        return False\n",
    "    biword = current + \" \" + nextt\n",
    "    # if the phrase is in the Brys. dictionary, flag it as a biword\n",
    "    if bigrams.get(biword) != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def collect_bigram(sentence):\n",
    "    return None\n",
    "\n",
    "def collect_bnc_examples(ratings_dict, max_num_examples=50, override=False):\n",
    "    import os.path\n",
    "    import csv\n",
    "    \n",
    "    #pathname = './data/bnc_words_with_context_tokens.csv'\n",
    "    \n",
    "    # do we already have the data collected?\n",
    "    if os.path.isfile(pathname) and override==False:\n",
    "        print(\"data already exist at %s\" % pathname)\n",
    "        return\n",
    "    \n",
    "    else:    \n",
    "        bnc_reader = load_bnc()\n",
    "        corpus = bnc_reader.tagged_sents(strip_space=True)\n",
    "        corpus_length = len(corpus)\n",
    "        print(\"# Sentences in BNC corpus: %s\" % corpus_length)\n",
    "\n",
    "        \n",
    "        #with open('./data/bnc_words_with_context_tokens.csv', mode='w') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter='\\t', quoting=csv.QUOTE_NONNUMERIC)\n",
    "            \n",
    "            # create data structures for keeping tabs on how many tokens we have collected\n",
    "            unigrams = {}\n",
    "            bigrams = {}\n",
    "            for x in ratings.values():\n",
    "                word = x[\"word\"]\n",
    "                if x[\"bigram\"] == True:\n",
    "                    bigrams[word]=max_num_examples\n",
    "                else:\n",
    "                    unigrams[word]=max_num_examples\n",
    "                    \n",
    "            \n",
    "            # come up with a random order in which to traverse the BNC\n",
    "            randomized_indexes = randomly([x for x in range(corpus_length-1)])\n",
    "            \n",
    "            \"\"\"\"\n",
    "            Iterate through the corpus, looking at words one by one, and \n",
    "            keep iterating as long as we still have tokens to collect\n",
    "            \"\"\"\n",
    "            while (bigrams or unigrams) and randomized_indexes:\n",
    "                corpus_index = randomized_indexes.pop()\n",
    "                sentence = corpus[corpus_index]\n",
    "                i = 0\n",
    "               \n",
    "                # check if we should collect sentence as a token for some brysbaert unigram or bigram\n",
    "                for word_tuple in sentence:\n",
    "                \n",
    "                    current_token = current_word(i, sentence)\n",
    "                    next_token = next_word(i, sentence)\n",
    "                    \n",
    "                    # first check if its a multi-word expression\n",
    "                    bigram = is_biword(current_token, next_token, bigrams)\n",
    "                    \n",
    "                    # collect bigram token\n",
    "                    if bigram:\n",
    "                        biword = current_token + \" \" + next_token\n",
    "                        tag = \"\"\n",
    "                        string = ' '.join([w[0] for w in sentence])\n",
    "                        #entry = \"%s\\t%s\\t%s\\t%s\\n\" % (biword, string, tag, corpus_index)                            \n",
    "                        #disk.write(entry)\n",
    "                        writer.writerow([biword, string, tag, corpus_index])\n",
    "                        bigrams[biword] -= 1\n",
    "                        if bigrams[biword] == 0:\n",
    "                            del bigrams[biword]\n",
    "                \n",
    "                    #otherwise check if it should be collected as a unigram and collect\n",
    "                    else:\n",
    "                        word = word_tuple[0]\n",
    "                        tag = word_tuple[1]\n",
    "                        string = ' '.join([w[0] for w in sentence])\n",
    "                        \n",
    "                        token_count = unigrams.get(word) \n",
    "                        if token_count != None:\n",
    "                            #entry = \"%s\\t%s\\t%s\\t%s\\n\" % (word, string, tag, corpus_index)\n",
    "                            #disk.write(entry)\n",
    "                            writer.writerow([word, string, tag, corpus_index])\n",
    "                            unigrams[word] -=1\n",
    "                            if unigrams[word]==0:\n",
    "                                del unigrams[word]\n",
    "                        \n",
    "                    i+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#collect_bnc_examples(ratings, override = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some stats on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the average number of examples for each word?\n",
    "#os.system(\"awk 'BEGIN {FS=OFS=\"\\t\"} NR > 0 {a[$1]+=1} END {for (i in a) {print i, a[i]}}' bnc_words_with_context_tokens.txt | sort -n >> bnc_counts.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tokens for 19370 words\n",
      "Over 20 tokens for 24086 words\n",
      "Over 10 tokens for 27235 words\n",
      "Less than 20 tokens for 11247 words\n",
      "                   word  count  concreteness\n",
      "0                   sat     49          3.88\n",
      "1                  back     49          4.33\n",
      "2                    in     49          3.00\n",
      "3                   her     49          3.00\n",
      "4                 chair     49          4.58\n",
      "...                 ...    ...           ...\n",
      "27230      orchestrator     10          4.03\n",
      "27231  internationality     12          2.28\n",
      "27232             byway     10          3.32\n",
      "27233           lowlife     10          3.27\n",
      "27234         worldview     11          2.31\n",
      "\n",
      "[27235 rows x 3 columns]\n",
      "Index(['word', 'count', 'concreteness'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, '')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import matplotlib\n",
    "import seaborn as sns, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#############\n",
    "# How many do we keep if we want 20 examples minimum? 10?\n",
    "##############\n",
    "with open('../../abstract_bert/data/bnc_words_with_context_tokens.csv', mode=\"r\") as infile:\n",
    "    reader = csv.reader(infile, delimiter=\"\\t\")\n",
    "    #token_counts = {row[0]:int(row[1]) for row in reader}\n",
    "    token_counts = {}\n",
    "    for row in reader:\n",
    "        word = row[0]\n",
    "        if word in token_counts:\n",
    "            token_counts[word] += 1\n",
    "        else:\n",
    "            token_counts[word] = 0\n",
    "    \n",
    "    fifty = [(x, y, ratings_dict[x]) for (x,y) in token_counts.items() if y >=49]\n",
    "    over_twenty = {x: y for (x,y) in token_counts.items() if y >=20}\n",
    "    less_than_twenty = {x: y for (x,y) in token_counts.items() if y <20}\n",
    "    over_ten = [[x, y, ratings[x][\"concreteness\"]] for (x,y) in token_counts.items() if y >=10]\n",
    "    print(\"50 tokens for %s words\" %len(fifty))\n",
    "    print(\"Over 20 tokens for %s words\" %len(over_twenty))\n",
    "    print(\"Over 10 tokens for %s words\" %len(over_ten))\n",
    "    print(\"Less than 20 tokens for %s words\" %len(less_than_twenty))\n",
    "\n",
    "################\n",
    "# What's the relationship betweeen abstractness and frequency in the corpus? We want this to be relatively even, I think....\n",
    "################\n",
    "\n",
    "df = pd.DataFrame.from_records(over_ten, columns=[\"word\", \"count\", \"concreteness\"])\n",
    "print(df)\n",
    "print(df.columns)\n",
    "\n",
    "# Cut the window in 2 parts\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "\n",
    "# Add a graph in each part\n",
    "sns.boxplot(df[\"concreteness\"], ax=ax_box)\n",
    "sns.distplot(df[\"concreteness\"], ax=ax_hist)\n",
    "\n",
    " \n",
    "# Remove x axis name for the boxplot\n",
    "ax_box.set(xlabel='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to the distribution of ratings in the entire Brysbaert data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  word  concreteness\n",
      "0          roadsweeper          4.85\n",
      "1          traindriver          4.54\n",
      "2                 tush          4.45\n",
      "3            hairdress          3.93\n",
      "4        pharmaceutics          3.77\n",
      "...                ...           ...\n",
      "39949         unenvied          1.21\n",
      "39950     agnostically          1.20\n",
      "39951  conceptualistic          1.18\n",
      "39952  conventionalism          1.18\n",
      "39953    essentialness          1.04\n",
      "\n",
      "[39954 rows x 2 columns]\n",
      "Index(['word', 'concreteness'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, '')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(list(ratings.values()), columns=[\"word\", \"concreteness\"])\n",
    "print(df)\n",
    "print(df.columns)\n",
    "\n",
    "# Cut the window in 2 parts\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "\n",
    "\n",
    "# Add a graph in each part\n",
    "sns.boxplot(df[\"concreteness\"], ax=ax_box)\n",
    "sns.distplot(df[\"concreteness\"], ax=ax_hist)\n",
    "\n",
    " \n",
    "# Remove x axis name for the boxplot\n",
    "ax_box.set(xlabel='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "ALLWORDS_DIR = './data/brysbaert_word_data'\n",
    "\n",
    "# you already have tokens collected for each word in simlex and wordsim\n",
    "# now these tokens ought to be sorted into their own files\n",
    "\n",
    "# ensure that there is a word_data directory to store in our words\n",
    "# you have to delete it first with rm -rf if we are reloading\n",
    "os.mkdir(ALLWORDS_DIR)\n",
    "\n",
    "\n",
    "# create files for each word we care about\n",
    "for word in ratings.keys():\n",
    "    word_dir = os.path.join(ALLWORDS_DIR, word)\n",
    "    os.mkdir(word_dir)\n",
    "\n",
    "\n",
    "# read in the big long file\n",
    "with open('./data/bnc_words_with_context_tokens.csv', mode=\"r\") as infile:\n",
    "    fieldnames = [\"word\", \"sentence\", \"POS\", \"id\"]\n",
    "    reader = csv.DictReader(infile, delimiter=\"\\t\", quoting=csv.QUOTE_NONNUMERIC, fieldnames=fieldnames)\n",
    "    \n",
    "    # split the big long file into smaller, sorted files that are easier to process one at a time\n",
    "    for row in reader:\n",
    "        \n",
    "        word = row[\"word\"]\n",
    "        text = row[\"sentence\"]\n",
    "        pos = row[\"POS\"]\n",
    "        uid = \"BNC_\" + str(int(row[\"id\"]))\n",
    "\n",
    "        # open file for this word to spit tokens into\n",
    "        token_file = os.path.join(ALLWORDS_DIR, word, \"BNC_tokens.csv\")\n",
    "        with open(token_file, mode=\"a\") as outfile:\n",
    "            # finally, write all of the info with the vector to disk\n",
    "            writer = writer = csv.writer(outfile, delimiter='\\t', quoting=csv.QUOTE_NONNUMERIC)\n",
    "            writer.writerow([word, text, pos, uid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-pretrained-bert\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate variance for word at layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# bert base uncased\n",
    "import numpy as np\n",
    "import csv\n",
    "import bert_helper\n",
    "import os, shutil\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for each word file we have, do the following:\n",
    "    for each layer we care about, calculate the token embedding at that layer for each token\n",
    "        for each number of clusters we care about, calculate\n",
    "            the centroids of those clusters\n",
    "            the variance within that cluster\n",
    "        \n",
    "store results in a file, one for each word+layer+cluster_number combo, resulting in a file structure like the following:\n",
    "\n",
    "brysbaert_word_data/\n",
    "  |-airplane/\n",
    "  | |- bnc_tokens.csv\n",
    "  | |- layer_0_k_1_clusters.csv\n",
    "  | |   ...\n",
    "  | |- layer_0_k_7_clusters.csv\n",
    "  | |   ...\n",
    "  | |- layer_11_k_7_clusters.csv\n",
    "  \n",
    "each cluster file is a csv with the following fields:\n",
    "    word\n",
    "    layer\n",
    "    cluster_size_k\n",
    "    cluster_number\n",
    "    centroid\n",
    "    token_ids\n",
    "    within_cluster_variance\n",
    "    concreteness\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "2) the layers we want to analzye\n",
    "\"\"\"\n",
    "layers = [0,1,5,11]\n",
    "\n",
    "\"\"\"\n",
    "3) The cluster sizes we want to analyze\n",
    "\"\"\"\n",
    "cluster_sizes = [1,3,5,7]\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "(model, tokenizer) = bert_helper.initialize()\n",
    "\n",
    "i = 0\n",
    "for word in ratings.keys():\n",
    "    i+=1\n",
    "    if i % 100 == 0:\n",
    "        print(\"processed %s words\" % i)\n",
    "        print(\"calculating clusters for %s\" % word)\n",
    "\n",
    "    # it's more efficient to collect all the vectors for all the layers at once,\n",
    "    # since we calculate the whole activation network at once for each token\n",
    "    vectors = []\n",
    "\n",
    "    \n",
    "    # create a directory to store all our clustering results in\n",
    "    data_dir = './data/brysbaert_word_data'\n",
    "    results_dir = os.path.join(data_dir, word, 'analysis_results')    \n",
    "    if os.path.exists(results_dir):\n",
    "        shutil.rmtree(results_dir)\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "    # read in the tokens for this word\n",
    "    pathname = os.path.join(data_dir, word, 'BNC_tokens.csv')\n",
    "    if os.path.isfile(pathname):\n",
    "        with open(pathname, mode='r') as csv_file:\n",
    "            reader = csv.DictReader(csv_file, delimiter='\\t', fieldnames=[\"word\", \"sentence\", \"tag\", \"uid\"])\n",
    "\n",
    "            data = [row for row in reader]\n",
    "\n",
    "            # generate embeddings for each token\n",
    "            for row in data:\n",
    "                sentence = row[\"sentence\"]\n",
    "                vector = bert_helper.get_bert_vectors_for(word, sentence, model, tokenizer)\n",
    "                # if the token was too long we may not have succeeded in generating embeddings for it, in which case we will throw it out\n",
    "                if vector != None:\n",
    "                    row[\"embedding\"] = vector\n",
    "                else:\n",
    "                    row[\"embedding\"] = None\n",
    "            data = list(filter(lambda row: row[\"embedding\"] != None, data))\n",
    "\n",
    "            for layer in layers:\n",
    "                layer_vectors = [row[\"embedding\"][layer] for row in data]\n",
    "\n",
    "                for k in cluster_sizes:\n",
    "                    if len(data) >= k:\n",
    "                        # calculate clusters\n",
    "                        kmeans_obj = KMeans(n_clusters=k)\n",
    "                        kmeans_obj.fit(layer_vectors)\n",
    "                        label_list = kmeans_obj.labels_\n",
    "                        cluster_centroids = kmeans_obj.cluster_centers_\n",
    "\n",
    "\n",
    "                        # store clusternumber with data\n",
    "                        for index,datapoint in enumerate(data):\n",
    "                            datapoint['cluster_number'] = label_list[index]\n",
    "\n",
    "                        # generate outfile name\n",
    "                        filename = \"layer_\" + str(layer) + \"_clusters_k_equals_\" + str(k) + \".csv\"\n",
    "                        outpath = os.path.join(results_dir, filename)\n",
    "\n",
    "\n",
    "                        with open(outpath, mode='w') as disk:\n",
    "                            writer = csv.DictWriter(disk, delimiter='\\t', fieldnames=['word', 'clusternumber', 'centroid', 'sentence_uids', 'variance', 'concreteness'])\n",
    "\n",
    "\n",
    "                            # retrieve centroid for each cluster and uids of sentences in cluster:\n",
    "                            for clusternumber in range(k):\n",
    "                                centroid = cluster_centroids[clusternumber]\n",
    "                                sentence_uids = []\n",
    "\n",
    "                                cluster_vectors = []\n",
    "                                # find the tokens in the dataset that are in this cluster\n",
    "                                for index, datapoint in enumerate(data):\n",
    "                                    if datapoint['cluster_number'] == clusternumber:\n",
    "                                        sentence_uids.append(datapoint['uid'])\n",
    "                                        cluster_vectors.append(layer_vectors[index])\n",
    "\n",
    "\n",
    "\n",
    "                                # calculate variance for this cluster\n",
    "                                # the sentence uids are the ones in this cluster. you need to get the vectors for them \n",
    "                                # and calculate variance.\n",
    "                                cluster_variance = np.var(cluster_vectors)\n",
    "\n",
    "\n",
    "                                out_data = {'word': word,\n",
    "                                            'clusternumber': clusternumber,\n",
    "                                            'centroid': centroid,\n",
    "                                            'sentence_uids': sentence_uids,\n",
    "                                            'variance': cluster_variance,\n",
    "                                            'concreteness': ratings[word]['concreteness']\n",
    "                                           }\n",
    "\n",
    "                                # store in file\n",
    "                                # write dta for this cluster\n",
    "                                writer.writerow(out_data)\n",
    "\n",
    "                    else:\n",
    "                        print(\"not enough tokens to make %s clusters for word: %s\" % (k, word))\n",
    "    else:\n",
    "        print(\"no data for %s\" % word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def index_sublist(sub, lst):\n",
    "    \"\"\"\n",
    "    Find a sublist in a list    \n",
    "    \"\"\"\n",
    "    if type(sub) == list:\n",
    "        sublen = len(sub)\n",
    "        first = sub[0] if sub else []\n",
    "    else:\n",
    "        raise ValueError\n",
    "    indx = -1\n",
    "    while True:\n",
    "        try:\n",
    "            indx = lst.index(first, indx + 1)\n",
    "        except ValueError:\n",
    "            break\n",
    "        if sub == lst[indx: indx + sublen]:\n",
    "            return indx\n",
    "    raise ValueError\n",
    "\n",
    "\n",
    "word = \"roadsweeper\"\n",
    "text = \"A roadsweeper is as a roadsweeper does, for all of life is but a road to be swept by a roadsweeper.\"\n",
    "\n",
    "tokenized_word = tokenizer.tokenize(word)\n",
    "print(tokenized_word)\n",
    "\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "\n",
    "\n",
    "               \n",
    "sublist_index = index_sublist(tokenized_word, tokenized_text)\n",
    "print(sublist_index)\n",
    "    \n",
    "\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "#for tup in zip(tokenized_text, indexed_tokens):\n",
    "    #print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "\n",
    "# Mark each of the tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "try:\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "except:\n",
    "    print(\"tokenized sequence too long\")\n",
    "    print(tokenized_text)\n",
    "\n",
    "# Rearrange hidden layers to be grouped by token\n",
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "token_embeddings.size()\n",
    "\n",
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings.size()\n",
    "\n",
    "\n",
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings.size()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "take the layer activations and get what you want from them. At this point,\n",
    "token_ebneddings is an array with length equal to the number of word pieces, \n",
    "and each item being a tensor with dimension 11 (1 for each layer), with a 768 \n",
    "vector at each dimension.\n",
    "\"\"\"\n",
    "vectors = []\n",
    "\n",
    "# find the index of the tokenized word pieces in the tokenized sentence\n",
    "start = index_sublist(tokenized_word, tokenized_text)\n",
    "length = len(tokenized_word)\n",
    "\n",
    "# calculate the embeddings for each word piece\n",
    "for i in range(length):\n",
    "    token_vec = token_embeddings[start]\n",
    "    token = tokenized_text[start]\n",
    "    print(token)\n",
    "    print(token_vec)\n",
    "    vec = token_vec[-1]\n",
    "    vectors.append(vec.numpy())\n",
    "    start+=1\n",
    "    \n",
    "word_vector = np.average(vectors, axis=0)\n",
    "\n",
    "word_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('./data/bnc_words_with_context_tokens.csv', mode=\"r\") as infile:\n",
    "            reader = csv.reader(infile, delimiter=\"\\t\")\n",
    "            i = 0\n",
    "            for row in reader:\n",
    "                i += 1\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the variance in the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
